{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29e8db9-fed9-4992-b291-7af9e1cca854",
   "metadata": {
    "id": "b29e8db9-fed9-4992-b291-7af9e1cca854"
   },
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import to_categorical\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdbb647-d73f-468d-b876-8a81499804a1",
   "metadata": {
    "id": "7bdbb647-d73f-468d-b876-8a81499804a1"
   },
   "outputs": [],
   "source": [
    "# The 3 classes\n",
    "labels = ['COVID', 'NORMAL', 'PNEUMONIA']\n",
    "\n",
    "# The image size is 256*256\n",
    "img_size = 256\n",
    "\n",
    "# Returns a list containing pairs of resized image arrays and their respective class numbers (0,1,2) for (COVID, NORMAL, PNEUMONIA)\n",
    "def get_data(data_dir):\n",
    "    data = []\n",
    "    for label in labels:\n",
    "        path = os.path.join(data_dir, label).replace(\"\\\\\", \"/\")\n",
    "        class_num = labels.index(label)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_path = os.path.join(path, img).replace(\"\\\\\", \"/\")\n",
    "                img_arr = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "                resized_arr = cv2.resize(img_arr, (img_size, img_size))\n",
    "                data.append([resized_arr, class_num])\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    return np.array(data, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c74d44d-b1cf-452e-9122-a6d51b894f0d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6c74d44d-b1cf-452e-9122-a6d51b894f0d",
    "outputId": "dc348326-34d1-47f8-ba66-3bcb92973b71"
   },
   "outputs": [],
   "source": [
    "# Training data 80%\n",
    "train = get_data('DataSet/Train') \n",
    "# Validation data 10%\n",
    "val = get_data('DataSet/Validation')\n",
    "# Testing data 10%\n",
    "test = get_data('DataSet/Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7d6231-b55f-4663-8813-ea45606594e5",
   "metadata": {
    "id": "bb7d6231-b55f-4663-8813-ea45606594e5"
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52772ad5-42d6-4fd5-a678-05f9e4d241fa",
   "metadata": {},
   "source": [
    "## Organizing and Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73208790-b0b7-4b3b-a93a-1100a4508152",
   "metadata": {
    "id": "73208790-b0b7-4b3b-a93a-1100a4508152"
   },
   "outputs": [],
   "source": [
    "# Contain the features and labels for the training set\n",
    "x_train = []\n",
    "y_train = []\n",
    "# Contain the features and labels for the validation set\n",
    "x_val = []\n",
    "y_val = []\n",
    "# Contain the features and labels for the testing set\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for feature, label in train:\n",
    "    x_train.append(feature) # Represents the image data\n",
    "    y_train.append(label)  # Represents the class label associated with the image\n",
    "    \n",
    "for feature, label in val:\n",
    "    x_val.append(feature) # Represents the image data\n",
    "    y_val.append(label) # Represents the class label associated with the image\n",
    "\n",
    "for feature, label in test:\n",
    "    x_test.append(feature) # Represents the image data\n",
    "    y_test.append(label) # Represents the class label associated with the image\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3bfac4-48e7-459c-aa7a-a3d215fdeabc",
   "metadata": {
    "id": "cf3bfac4-48e7-459c-aa7a-a3d215fdeabc"
   },
   "source": [
    "## Normalizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081da6f3-a313-46e2-a970-cb1a4186a757",
   "metadata": {
    "id": "081da6f3-a313-46e2-a970-cb1a4186a757"
   },
   "outputs": [],
   "source": [
    "# Normalization : Converts the image pixel values from the range [0, 255] to a normalized range [0, 1]\n",
    "x_train = np.array(x_train) / 255\n",
    "x_val = np.array(x_val) / 255\n",
    "x_test = np.array(x_test) / 255\n",
    "\n",
    "# resize data\n",
    "x_train = x_train.reshape(-1, img_size, img_size, 1)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "x_val = x_val.reshape(-1, img_size, img_size, 1)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "x_test = x_test.reshape(-1, img_size, img_size, 1)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da968a62-fa0f-45ca-9e09-2a7c945730e2",
   "metadata": {
    "id": "da968a62-fa0f-45ca-9e09-2a7c945730e2"
   },
   "source": [
    "## Data Augmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb97506-49a7-4d22-8ca0-7ecd029d18ad",
   "metadata": {
    "id": "8fb97506-49a7-4d22-8ca0-7ecd029d18ad"
   },
   "outputs": [],
   "source": [
    "# Data augmentation is a technique used to artificially increase the diversity of the training dataset\n",
    "# by applying various transformations to the existing images.\n",
    "# This helps the model generalize better to new, unseen data and reduce overfitting.\n",
    "\n",
    "datagen = ImageDataGenerator(rotation_range = 30,  \n",
    "        zoom_range = 0.2,\n",
    "        width_shift_range=0.1,  \n",
    "        height_shift_range=0.1,\n",
    "        horizontal_flip = True) \n",
    "\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cc9cd8-ef9f-4ca4-a349-23faf9de9f55",
   "metadata": {
    "id": "08cc9cd8-ef9f-4ca4-a349-23faf9de9f55"
   },
   "source": [
    "# Training the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4393d6ca-5c1a-4fe7-bd37-1369ad3b1cc5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4393d6ca-5c1a-4fe7-bd37-1369ad3b1cc5",
    "outputId": "96534ebe-f3e7-48b9-85b9-4619c35df9dc"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(img_size, img_size, 1))) # The input is a grayscale image\n",
    "model.add(MaxPool2D(pool_size=(2, 2))) # Reduce spatial dimension\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten()) # Transforms 2D to 1D\n",
    "model.add(Dense(64, activation='relu')) \n",
    "model.add(Dense(3, activation='softmax')) # Output layer => 3 classes\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'],run_eagerly=True)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd10d233-bc91-42fb-be25-d9c3b9030210",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cd10d233-bc91-42fb-be25-d9c3b9030210",
    "outputId": "eaf5eef8-d0f8-4406-e6fa-1f6e1b23634d"
   },
   "outputs": [],
   "source": [
    "# The original labels were integers representing classes ( 0, 1, 2 for COVID, NORMAL, PNEUMONIA)\n",
    "# to_categorical converts these into arrays where each element corresponds to a class,\n",
    "# and the label is marked as 1 in the respective class position while other positions are 0s.\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "y_train_encoded = to_categorical(y_train,num_classes=3)\n",
    "y_val_encoded = to_categorical(y_val,num_classes=3)\n",
    "# Define an EarlyStopping callback to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "#  Training the neural network model using the prepared data\n",
    "model.fit(datagen.flow(x_train, y_train_encoded, batch_size=128), epochs=15, verbose=1, validation_data=datagen.flow(x_val, y_val_encoded),callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf1c480-b096-4ff0-ba8b-bb006b2d76dc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "ecf1c480-b096-4ff0-ba8b-bb006b2d76dc",
    "outputId": "ee7dff1d-5880-4f9f-bd8d-17fdace3e4af"
   },
   "outputs": [],
   "source": [
    "# Assuming y_test is your original class labels (not one-hot encoded)\n",
    "y_test_encoded = to_categorical(y_test, num_classes=3)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "evaluation_result = model.evaluate(x_test, y_test_encoded)\n",
    "\n",
    "# Print the loss and accuracy\n",
    "print(\"Loss of the model is -\", evaluation_result[0])\n",
    "print(\"Accuracy of the model is -\", evaluation_result[1] * 100, \"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf9f9b0-8ec4-43c6-b163-40acb5e1f73a",
   "metadata": {
    "id": "fdf9f9b0-8ec4-43c6-b163-40acb5e1f73a"
   },
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7ca995-2f6a-40de-a6c7-8dff38521e21",
   "metadata": {
    "id": "aa7ca995-2f6a-40de-a6c7-8dff38521e21",
    "outputId": "76f9e5ac-013d-4448-d067-d92ec1a75087"
   },
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "# WIll be used to calculate confusion matrix\n",
    "predictions = model.predict(x_test)\n",
    "predictions = predictions.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa124632-df97-4172-9772-bb080b8960cc",
   "metadata": {
    "id": "fa124632-df97-4172-9772-bb080b8960cc"
   },
   "source": [
    "# Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e7640b-efd8-4f29-8050-2e652a7dda10",
   "metadata": {
    "id": "d9e7640b-efd8-4f29-8050-2e652a7dda10"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    # Open the image\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    # Resize the image\n",
    "    img = cv2.resize(img, (256,256))\n",
    "    # Normalize the pixel values to be in the range [0, 1]\n",
    "    img_array = np.array(img) / 255\n",
    "    # Add a batch dimension and reshape to match the model's input shape\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # (1, 256, 256, 1)\n",
    "\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685fb80a-3c83-4533-9e9a-6522a6ecff63",
   "metadata": {
    "id": "685fb80a-3c83-4533-9e9a-6522a6ecff63"
   },
   "outputs": [],
   "source": [
    "def process_image(image_path):\n",
    "    # The output image will be a grayscale, resized, normalized, and reshaped representation of the original image\n",
    "    preprocessed_image = preprocess_image(image_path)\n",
    "\n",
    "    # Make prediction on the single preprocessed image\n",
    "    prediction = model.predict(preprocessed_image)\n",
    "\n",
    "    # Get the index of the predicted class\n",
    "    predicted_class = prediction.argmax()\n",
    "    return predicted_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0c9cb4-97cd-4a04-a094-7e97180338c2",
   "metadata": {
    "id": "3a0c9cb4-97cd-4a04-a094-7e97180338c2",
    "outputId": "46beef67-e1f1-44b5-a7fd-1a1fc92e1538"
   },
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from PIL import ImageTk, Image\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "\n",
    "root = tk.Tk()\n",
    "root.title(\"Lung Illness Detection\")\n",
    "\n",
    "# Get the screen width and height\n",
    "screen_width = root.winfo_screenwidth()\n",
    "screen_height = root.winfo_screenheight()\n",
    "\n",
    "# Calculate the frame width and height as 75% of the screen\n",
    "frame_width = int(screen_width * 0.75)\n",
    "frame_height = int(screen_height * 0.75)\n",
    "\n",
    "# Set the frame dimensions\n",
    "root.geometry(f\"{frame_width}x{frame_height}\")\n",
    "\n",
    "frame = tk.Frame(root, bg='#CEDDD9', width=frame_width, height=frame_height)\n",
    "frame.pack_propagate(False)  # Disable frame auto-resizing\n",
    "frame.grid_propagate(False)  # Disable grid resizing\n",
    "frame.grid_rowconfigure(0, weight=1)  # Make row expandable\n",
    "frame.grid_columnconfigure(0, weight=1)  # Make column expandable\n",
    "\n",
    "lbl_show_pic = tk.Label(frame, bg='#CEDDD9') #Label of the selected image\n",
    "lbl_show_predictedClass = tk.Label(frame, bg='#CEDDD9', fg='#297C65', font=('verdana', 14, 'bold'))\n",
    "entry_show_predictedClass = tk.Entry(frame, font=('verdana',16)) #Value of the predicted class\n",
    "btn_browse = tk.Button(frame, text='Select Image', bg='grey', fg='#ffffff', font=('verdana', 16)) #Button select image\n",
    "btn_predict = tk.Button(frame, text='Predict', bg='#50AD94', fg='#ffffff', font=('verdana', 16)) #Button predict\n",
    "\n",
    "\n",
    "# The window that contains Accuracy and confusion matrix\n",
    "def open_new_window():\n",
    "    new_window = tk.Toplevel(root)\n",
    "    new_window.title(\"Informations\")\n",
    "\n",
    "    # Get the dimensions of the root frame\n",
    "    root_frame_width = frame.winfo_width()\n",
    "    root_frame_height = frame.winfo_height()\n",
    "\n",
    "    new_window.geometry(f\"{root_frame_width}x{root_frame_height}\")\n",
    "\n",
    "    frame1 = tk.Frame(new_window, bg='#CEDDD9', width=root_frame_width, height=root_frame_height)\n",
    "    frame1.pack_propagate(False)  # Disable frame auto-resizing\n",
    "    frame1.grid_propagate(False)  # Disable grid resizing\n",
    "    frame1.grid_rowconfigure(0, weight=1) # Make row expandable\n",
    "    frame1.grid_columnconfigure(0, weight=1)  # Make column expandable\n",
    "\n",
    "    # Label of accuracy\n",
    "    lbl_accuracy = tk.Label(frame1,text=\"Accuracy of the model is : \", bg='#CEDDD9', fg='#297C65', font=('verdana', 14, 'bold'))\n",
    "    lbl_value_accuracy = tk.Label(frame1,text=f\"{evaluation_result[1] * 100:.2f}%\", bg='#CEDDD9', fg='#000000', font=('verdana', 12, 'bold'))\n",
    "    lbl_accuracy.pack()\n",
    "    lbl_value_accuracy.pack()\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, predictions)\n",
    "    labels = ['COVID', 'NORMAL', 'PNEUMONIA']\n",
    "\n",
    "    # Create a DataFrame for the confusion matrix\n",
    "    cm_df = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "\n",
    "    # Create a heatmap\n",
    "    sns.heatmap(cm_df, cmap=\"Blues\", linecolor='black', linewidth=1, annot=True, fmt='', xticklabels=labels, yticklabels=labels)\n",
    "\n",
    "    # Save the plot as an image\n",
    "    plt.savefig('confusion_matrix.png') \n",
    "\n",
    "    # Display the confusion matrix image in the new window\n",
    "    img1 = Image.open('confusion_matrix.png')\n",
    "    img1 = img1.resize((512, 512), Image.ANTIALIAS)\n",
    "    img1 = ImageTk.PhotoImage(img1)\n",
    "\n",
    "    # Label of confusion matrix\n",
    "    lbl_matrice_confusion = tk.Label(frame1, text=\"Confusion Matrix : \", bg='#CEDDD9', fg='#297C65', font=('verdana', 14, 'bold'))\n",
    "    lbl_matrice_confusion.pack()\n",
    "    lbl_show_matrice_confusion = tk.Label(frame1, bg='#CEDDD9', image=img1)\n",
    "    lbl_show_matrice_confusion.image = img1 \n",
    "    lbl_show_matrice_confusion.pack()\n",
    "\n",
    "    frame1.pack()\n",
    "\n",
    "# On Hover button Informations\n",
    "class ToolTip:\n",
    "    def __init__(self, widget, text):\n",
    "        self.widget = widget\n",
    "        self.text = text\n",
    "        self.tooltip_window = None\n",
    "        self.widget.bind(\"<Enter>\", self.show_tooltip)\n",
    "        self.widget.bind(\"<Leave>\", self.hide_tooltip)\n",
    "\n",
    "    def show_tooltip(self, event=None):\n",
    "        x, y, _, _ = self.widget.bbox(\"insert\")\n",
    "        x += self.widget.winfo_rootx() + 25\n",
    "        y += self.widget.winfo_rooty() + 25\n",
    "\n",
    "        self.tooltip_window = tk.Toplevel(self.widget)\n",
    "        self.tooltip_window.wm_overrideredirect(True)\n",
    "        self.tooltip_window.wm_geometry(f\"+{x}+{y}\")\n",
    "\n",
    "        label = tk.Label(self.tooltip_window, text=self.text, bg=\"#ffffff\", relief=\"solid\", borderwidth=1)\n",
    "        label.pack()\n",
    "\n",
    "    def hide_tooltip(self, event=None):\n",
    "        if self.tooltip_window:\n",
    "            self.tooltip_window.destroy()\n",
    "            self.tooltip_window = None\n",
    "\n",
    "# Create the tooltip for the button\n",
    "tooltip_text = \"Show accuracy and confusion matrix\"\n",
    "btn_show_info = ImageTk.PhotoImage(file='info.png')\n",
    "btn_info = tk.Button(frame, bg='#CEDDD9', image=btn_show_info, command=open_new_window)\n",
    "btn_info.grid(row=4, column=0, sticky=tk.SE)\n",
    "tooltip = ToolTip(btn_info, tooltip_text)\n",
    "\n",
    "# Create space from the bottom and right edges\n",
    "frame.grid_rowconfigure(5, minsize=20)\n",
    "frame.grid_columnconfigure(1, minsize=20) \n",
    "\n",
    "# Will contain the selected image path\n",
    "filename=\"\"\n",
    "\n",
    "# Function called when we select an image\n",
    "def selectPic():\n",
    "    global img, filename\n",
    "    filename = filedialog.askopenfilename(initialdir=\"/images\", title=\"Select Image\",\n",
    "                                          filetypes=((\"png images\", \"*.png\"), (\"jpg images\", \"*.jpg\")))\n",
    "    # Display the image\n",
    "    img = Image.open(filename)\n",
    "    img = img.resize((256, 256), Image.ANTIALIAS)\n",
    "    img = ImageTk.PhotoImage(img)\n",
    "    lbl_show_pic['image'] = img\n",
    "    lbl_show_pic.grid(row=0, column=0, padx=20, pady=20, sticky=tk.W + tk.E + tk.N + tk.S)\n",
    "    # Display a new button to predict the image's class\n",
    "    btn_predict.grid(row=2, column=0, padx=10, pady=10, sticky=tk.N)\n",
    "\n",
    "# Function called when we press the predict button\n",
    "def predictPic():\n",
    "    # Display predicted class\n",
    "     lbl_show_predictedClass.grid(row=3, column=0, padx=20, pady=20, sticky=tk.W + tk.E + tk.N + tk.S)\n",
    "     predicted_class = process_image(filename)\n",
    "     lbl_show_predictedClass.config(text=\"Predicted class : \"+labels[predicted_class])\n",
    "\n",
    "\n",
    "btn_browse['command'] = selectPic # Select image button\n",
    "btn_predict['command'] = predictPic # Predict class button\n",
    "\n",
    "# Display the select image button\n",
    "btn_browse.grid(row=1, column=0, padx=10, pady=10, sticky=tk.N)\n",
    "\n",
    "frame.pack()\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db21708-ea2b-4c9a-bcd8-bf1a34416d17",
   "metadata": {
    "id": "3db21708-ea2b-4c9a-bcd8-bf1a34416d17",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "my-python3-kernel",
   "language": "python",
   "name": "my-python3-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
